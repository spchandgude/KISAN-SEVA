{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (6200, 5)\n",
      "\n",
      "Features: Index(['temperature', 'humidity', 'ph', 'rainfall', 'label'], dtype='object')\n",
      "\n",
      "Feature matrix:\n",
      "    temperature   humidity        ph    rainfall\n",
      "0    25.547599  91.641948  5.702485  212.867626\n",
      "1    31.655312  60.132637  6.526692   66.690968\n",
      "2    23.461683  23.221976  5.645436   95.842534\n",
      "3    23.086593  83.555461  7.227746   71.840807\n",
      "4    23.750331  92.881605  5.570021  117.660283\n",
      "\n",
      "Response vector:\n",
      " 0         COCONUT\n",
      "1      BLACK GRAM\n",
      "2    KIDNEY BEANS\n",
      "3          COTTON\n",
      "4           APPLE\n",
      "Name: label, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "# reading csv file \n",
    "data = pd.read_csv('/home/spchandgude/Downloads/Crop-prediction/cpdata.csv') \n",
    "\n",
    "# shape of dataset \n",
    "print(\"Shape:\", data.shape) \n",
    "\n",
    "# column names \n",
    "print(\"\\nFeatures:\", data.columns) \n",
    "\n",
    "# storing the feature matrix (X) and response vector (y) \n",
    "X = data[data.columns[:-1]] \n",
    "y = data[data.columns[-1]] \n",
    "\n",
    "# printing first 5 rows of feature matrix \n",
    "print(\"\\nFeature matrix:\\n\", X.head()) \n",
    "\n",
    "# printing first 5 values of response vector \n",
    "print(\"\\nResponse vector:\\n\", y.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3720, 4)\n",
      "(2480, 4)\n",
      "(3720,)\n",
      "(2480,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1) \n",
    "  \n",
    "# printing the shapes of the new X objects \n",
    "print(X_train.shape) \n",
    "print(X_test.shape) \n",
    "  \n",
    "# printing the shapes of the new y objects \n",
    "print(y_train.shape) \n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN model accuracy: 0.8625\n",
      "Predictions: ['COCONUT' 'PIGEON PEAS']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1) \n",
    "  \n",
    "# training the model on training set \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "knn = KNeighborsClassifier(n_neighbors=3) \n",
    "knn.fit(X_train, y_train) \n",
    "  \n",
    "# making predictions on the testing set \n",
    "y_pred = knn.predict(X_test) \n",
    "from sklearn import metrics \n",
    "print(\"kNN model accuracy:\", metrics.accuracy_score(y_test, y_pred)) \n",
    "\n",
    "# making prediction for out of sample data \n",
    "sample = [[25, 91, 5, 212],[26, 8, 6, 200]]\n",
    "preds = knn.predict(sample) \n",
    " \n",
    "print(\"Predictions:\", preds) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crop_prediction.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib \n",
    "joblib.dump(knn, 'crop_prediction.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(open('crop_prediction.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['COCONUT', 'PIGEON PEAS'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: joblib\r\n",
      "Version: 0.14.1\r\n",
      "Summary: Lightweight pipelining: using Python functions as pipeline jobs.\r\n",
      "Home-page: https://joblib.readthedocs.io\r\n",
      "Author: Gael Varoquaux\r\n",
      "Author-email: gael.varoquaux@normalesup.org\r\n",
      "License: BSD\r\n",
      "Location: /home/spchandgude/.local/lib/python2.7/site-packages\r\n",
      "Requires: \r\n"
     ]
    }
   ],
   "source": [
    "!pip show joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
